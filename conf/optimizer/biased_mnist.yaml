defaults:
  - base_optimizer
name: Adam
args:
  lr: 1e-3
  weight_decay: 5e-4
epochs: 90
lr_scheduler:
  type: MultiStepLR
  args:
    milestones: [50, 70]
    gamma: 0.1